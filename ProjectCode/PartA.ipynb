{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedded structure has been chosen over the referencing structure. The embedded structure discourages data redundancy as no referring fields are required to be added as foreign keys to show relationships. The referencing structure, however, do require foreign keys to show relationships. The drawbacks of the embedded structure may be its troublesome to read or process. However, these are quite simple solutions through the pretty print method allowing for us to easily format and understand the structure, and the unwind method to easily flatte then the data structure so processing and aggregation can occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of the embedded model without no hotspots is as follows:\n",
    "\n",
    "<code> {'GHI_w/m2': 156,\n",
    " '_id': ObjectId('60abb6caf7b620cbe44e88d0'),\n",
    " 'air_temperature_celcius': 19,\n",
    " 'date': datetime.datetime(2018, 12, 12, 0, 0),\n",
    " 'max_wind_speed': 12.0,\n",
    " 'precipitation ': 0.0,\n",
    " 'relative_humidity': 55.3,\n",
    " 'station': 948702,\n",
    " 'windspeed_knots': 6.2}</code>\n",
    "\n",
    "As you can see from the above document, there isn't any embedded fields which is due to the fact that there are no hotspots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an exmaple of the embedded model with hotspots.\n",
    "\n",
    "<code>{'GHI_w/m2': 159,\n",
    " '_id': ObjectId('60abb6caf7b620cbe44e87c9'),\n",
    " 'air_temperature_celcius': 20,\n",
    " 'average_surface_temp': 49.0,\n",
    " 'date': datetime.datetime(2018, 3, 24, 0, 0),\n",
    " 'hotspot_location': [{'confidence': 65,\n",
    "                       'date': datetime.datetime(2018, 3, 24, 0, 0),\n",
    "                       'datetime': '2018-03-24T04:58:00',\n",
    "                       'latitude': -37.1603,\n",
    "                       'longitude': 142.8088,\n",
    "                       'surface_temperature_celcius': 50},\n",
    "                      {'confidence': 55,\n",
    "                       'date': datetime.datetime(2018, 3, 24, 0, 0),\n",
    "                       'datetime': '2018-03-24T04:56:10',\n",
    "                       'latitude': -37.1684,\n",
    "                       'longitude': 142.8183,\n",
    "                       'surface_temperature_celcius': 48}],\n",
    " 'max_wind_speed': 11.1,\n",
    " 'precipitation ': 0.0,\n",
    " 'relative_humidity': 58.4,\n",
    " 'report': 'I',\n",
    " 'station': 948701,\n",
    " 'windspeed_knots': 6.1} </code>\n",
    " \n",
    " As we can see that there are two hotspots as the field 'hotspot_location' contains two elements in its array.\n",
    " This is the embedded structure or informally / colloqiually known as the nested structure. Not to mention, this format provides is the most space efficient format as no extra fields are required to be added to the structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required dependencies\n",
    "import csv\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "client = MongoClient()\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining variables which will be used for pymongo commands\n",
    "db = client.fit3182_assignment_db\n",
    "climate_historic = db.climate_historic\n",
    "unwound = db.unwound\n",
    "q2f = db.q2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropping existing databases before creating the new database\n",
    "climate_historic.drop()\n",
    "unwound.drop()\n",
    "q2f.drop()\n",
    "embedded.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('climate_historic.csv') as csv_file: # Opening csv file\n",
    "    csv_reader = csv.DictReader(csv_file) # Using DictReader makes into Json Files\n",
    "    for row in csv_reader: # Goes through each Json record and ensures correct data types as all was initialised as strings\n",
    "        row['date'] = pandas.to_datetime(row['date'],dayfirst=True)\n",
    "        row['station'] = int(row['station'])\n",
    "        row['air_temperature_celcius'] = int(row['air_temperature_celcius'])\n",
    "        row['relative_humidity'] = float(row['relative_humidity'])\n",
    "        row['windspeed_knots'] = float(row['windspeed_knots'])\n",
    "        row['max_wind_speed'] = float(row['max_wind_speed'])\n",
    "        row['GHI_w/m2'] = int(row['GHI_w/m2'])\n",
    "        row['report'] = str(row['precipitation '][-1]) # Separate precipitation to make apppropriate data type\n",
    "        row['precipitation '] = float(row['precipitation '][1:-2])\n",
    "        row['average_surface_temp'] = 'N/A' # THis is needed to compute the average surface temperature later on\n",
    "        row['hotspot_location'] = [] # Needed for later aggregation\n",
    "        climate_historic.insert_one(row) #Insert Json record to database\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hotspot_historic.csv') as csv_file:# Opening csv file\n",
    "    csv_reader = csv.DictReader(csv_file) # Using DictReader makes into Json Files\n",
    "    for row in csv_reader: # Goes through each Json record and ensures correct data types as all was initialised as strings\n",
    "        row['latitude'] = float(row['latitude'])\n",
    "        row['longitude'] = float(row['longitude'])\n",
    "        row['confidence'] = int(row['confidence'])\n",
    "        row['date'] = pandas.to_datetime(row['date'],dayfirst=True)\n",
    "        row['surface_temperature_celcius'] = int(row['surface_temperature_celcius'])\n",
    "        climate_historic.update_one({'date':row['date']},{'$push':{'hotspot_location':row}}) # We match by date and push the entire document to the climate record\n",
    "        x= climate_historic.find_one({'date':row['date']})['average_surface_temp'] # Calculation of average\n",
    "        if x == 'N/A':\n",
    "            new_average = row['surface_temperature_celcius'] # In the case of no hotspot embedded yet, change N/A to hotspot surface temp\n",
    "        else:\n",
    "            n=[i for i in climate_historic.aggregate([{'$match':{'date':row['date']}},\n",
    "                                           {'$project':{'no_of_fires':{'$size':'$hotspot_location'}}}])][0]['no_of_fires']#Finds number of fires in one date by grabbing length of list\n",
    "            new_average = x*(n-1) # Multiply by number of fires -1\n",
    "            new_average+=row['surface_temperature_celcius'] # Add new fire\n",
    "            new_average/= n # Divide by number of fires for new average\n",
    "            \n",
    "        climate_historic.update_one({'date':row['date']},{'$set':{'average_surface_temp': new_average}}) # Update the new average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: unwond only has documents that have hotspots\n",
    "# Creating new collection called unwound which unwinds hotsot data for future use\n",
    "res = climate_historic.aggregate([{'$unwind':'$hotspot_location'}])\n",
    "i = 0\n",
    "for doc in res:\n",
    "    doc['_id'] = i #Creating unique index\n",
    "    unwound.insert_one(doc) #Inserting doc\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = climate_historic.find()\n",
    "for doc in x:\n",
    "    pprint(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = climate_historic.find({\"date\": pandas.to_datetime(\"12/12/2018\")},{\"air_temperature_celcius\":1, \"date\":1, \"max_wind_speed\":1, \"precipitation \":1, \"relative_humidity\":1, \"station\":1 , \"windspeed_knots\":1, \"GHI_w/m2\":1}) # Finding climate data on 12/12/2018 with projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in res:\n",
    "    pprint(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = 'hotspot_location.surface_temperature_celcius'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unwound.find({'$and':[{long:{'$gte':65}}, {long:{'$lte':100}}]}).count() # finding the hotspot data with surfae temp betwen 65 and 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = unwound.find({'$and':[{long:{'$gte':65}}, {long:{'$lte':100}}]},{\"hotspot_location.latitude\":1, \"hotspot_location.longitude\":1, \"hotspot_location.surface_temperature_celcius\":1, \"hotspot_location.confidence\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in res:\n",
    "    pprint(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = unwound.find({\"$or\":[{\"date\": pandas.to_datetime(\"15/12/2018\")},{\"date\":pandas.to_datetime(\"16/12/2018\")}]},{\"date\":1, \"hotspot_location.surface_temperature_celcius\":1, \"air_temperature_celcius\":1, \"relative_humidity\":1, \"max_wind_speed\":1}) #finding data for the 15th and 16th December with correct projections\n",
    "for d in x:\n",
    "    pprint(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = \"hotspot_location.confidence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = unwound.find({'$and':[{long:{'$gte':80}}, {long:{'$lte':100}}]},{\"hotspot_location.datetime\":1, \"air_temperature_celcius\":1, \"hotspot_location.surface_temperature_celcius\":1, \"hotspot_location.confidence\":1}) #finding records where confidence is between 80 and 100 with correct projections\n",
    "for d in x:\n",
    "    pprint(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = unwound.find({}).sort(\"hotspot_location.surface_temperature_celcius\", -1).limit(10) #sorting on surface temperature in descending order and using .limit for top 10 records\n",
    "for result in results:\n",
    "    pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = climate_historic.aggregate([{\"$project\":{\"_id\":0,\"date\":1,\"fires\":{\"$size\":\"$hotspot_location\"}}}]) #number of fires based on the size of the hotspot_location array \n",
    "for document in results: \n",
    "    pprint(document) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded.drop()\n",
    "q2f.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = \"hotspot_location.confidence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = unwound.find({long:{'$lt':70}}) # finding records with confidence below 70\n",
    "for d in x:\n",
    "    pprint(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = climate_historic.aggregate([{\"$project\":{\"_id\":0,\"date\":1,\"average_surface_temp\":1}}]) #avg surface temp has already been calculated and is simply projected\n",
    "for document in results: \n",
    "    pprint(document) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = climate_historic.find().sort(\"GHI_w/m2\").limit(10) #Using limit to see top 10 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in y:\n",
    "    pprint(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = climate_historic.find({'$and':[{'report': 'G'},{'precipitation ': {'$gte':0.20}},{'precipitation ':{'$lte': 0.35}}]}) # Using and to fulfil multiple conditions including report, prefixed I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in x:\n",
    "    pprint(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
